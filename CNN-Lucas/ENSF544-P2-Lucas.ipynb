{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import itertools\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Conv1D, MaxPool1D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import scipy\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"/Users/lucasion/Documents/GitHub/seng544-proj-2/CNN-Lucas/cleaned_tweets.csv\")\n",
    "# test = pd.read_csv(\"/Users/lucasion/Documents/GitHub/seng544-proj-2/CNN-Lucas/test.csv\")\n",
    "\n",
    "Y_train = train[\"country\"]\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y_train)\n",
    "Y_train = le.transform(Y_train)\n",
    "\n",
    "X_train = train[\"text\"]\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X_train = cv.fit_transform(X_train)\n",
    "\n",
    "\n",
    "\n",
    "# # Reshape\n",
    "# X_train = X_train.values.reshape(-1, 28, 28, 1)\n",
    "# test = test.values.reshape(-1, 28, 28, 1)\n",
    "\n",
    "\n",
    "\n",
    "# One-hot encoding\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "Y_train = enc.fit_transform(Y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Split the train and the validation set for the fitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.1, random_state=2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=2)\n",
    "\n",
    "print(X_train.shape)\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=8, kernel_size=(5), padding='Same', activation='relu', input_shape=(X_train.shape)))\n",
    "model.add(MaxPool1D(pool_size=(2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(filters=16, kernel_size=(3), padding='Same', activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=(2), strides=(2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fully connected\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "epochs = 10\n",
    "batch_size = 250\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "scipy.sparse.csr_matrix.sort_indices(X_train)\n",
    "scipy.sparse.csr_matrix.sort_indices(Y_train)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, Y_train,\n",
    "                              epochs=epochs, \n",
    "                             )\n",
    "\n",
    "#  validation_data = (X_val, Y_val)\n",
    "df = pd.DataFrame(model.predict(X_test))\n",
    "df.to_csv(\"test_predict.csv\")\n",
    "\n",
    "df = pd.DataFrame(Y_test)\n",
    "df.to_csv(\"test_actual.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fcb00819dde9475f3b0217d122f11c977080c5f8afaee640ba5f37ba0d3f2a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
